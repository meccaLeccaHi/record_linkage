{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database name: mdc_2017_09_07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Import python modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Load 'helper utilities'\n",
    "from linkage_tools import *\n",
    "l = Linker()\n",
    "print('database name: '+l.connection.db)\n",
    "\n",
    "# Load classifier objects\n",
    "from Probabilistic import *\n",
    "from Perceptron import *\n",
    "from NeuralNetwork import *\n",
    "from KerasModel import *\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('error')\n",
    "\n",
    "# Display the output of plotting commands inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set print output toggle\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define linking variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define tables\n",
    "tableA = '''patient_discharges JOIN newborns\n",
    "ON patient_discharges.id = newborns.patient_discharge_id\n",
    "LEFT OUTER JOIN patient_payers AS newborn_payers\n",
    "ON newborn_payers.patient_discharge_id = patient_discharges.id'''\n",
    "\n",
    "tableB = '''births JOIN deliveries \n",
    "ON births.delivery_id = deliveries.id\n",
    "JOIN patient_discharges AS delivery_discharges\n",
    "ON deliveries.patient_discharge_id = delivery_discharges.id\n",
    "LEFT OUTER JOIN patient_payers AS delivery_payers\n",
    "ON delivery_payers.patient_discharge_id = delivery_discharges.id'''\n",
    "\n",
    "# Define fields to compare tables by\n",
    "tableA_fields = ['patient_discharges.sex_id','newborns.id','newborns.cesarean_section', \n",
    "            'patient_discharges.zip_code','patient_discharges.race_id','patient_discharges.ethnicity_id', \n",
    "                'newborn_payers.payer_type_of_coverage_id','patient_discharges.principal_language_spoken', \n",
    "                 'patient_discharges.discharged_on','newborn_payers.payer_category_id',\n",
    "                 'newborn_payers.plan_code_number','newborns.birth_weight_group_id',\n",
    "                 'newborns.gestational_age_group_id','newborns.plurality_group_id']\n",
    "\n",
    "tableB_fields = ['births.sex_id','births.newborn_id','births.delivery_route_id', \n",
    "            'births.mothers_residence_zip_code','delivery_discharges.race_id','delivery_discharges.ethnicity_id', \n",
    "                'delivery_payers.payer_type_of_coverage_id','delivery_discharges.principal_language_spoken', \n",
    "                 'delivery_discharges.discharged_on','delivery_payers.payer_category_id',\n",
    "                 'delivery_payers.plan_code_number','births.birth_weight',\n",
    "                 'births.gestational_age_ob_estimate','births.plurality'] \n",
    "\n",
    "# Define new names for each comparison\n",
    "simple_feature_names = ['sex_id','c_section','zip_code','race','ethnicity','payer_type_of_coverage_id',\n",
    "                'language_spoken','discharge','payer_category_id','plan_code_number','plurality']\n",
    "\n",
    "complex_feature_names = ['weight_group_id','gest_age_group_id']\n",
    "\n",
    "simple_feature_num = 11\n",
    "\n",
    "# Exact matching only\n",
    "simple_features = [val for pair in zip([x+'_match' for x in simple_feature_names],\n",
    "                                    [x+'_nomatch' for x in simple_feature_names]) for val in pair]\n",
    "\n",
    "# Including non-exact matching\n",
    "complex_features = [val for pair in zip([x+'_match' for x in complex_feature_names],\n",
    "                     [x+'_fuzzymatch' for x in complex_feature_names],\n",
    "                     [x+'_nomatch' for x in complex_feature_names]) for val in pair]\n",
    "\n",
    "feature_vals = simple_features + complex_features\n",
    "\n",
    "# Define bins to use for certain fields\n",
    "age_bins = np.concatenate(([0,1,24], np.arange(25, 36, 2),[99]), axis=0)\n",
    "bw_bins = np.concatenate(([1], np.arange(500, 2001, 250),[2500,9999]), axis=0)\n",
    "\n",
    "cesarean_ids = [1, 11, 21, 31, 2, 12, 22, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_condition_vals(cross_table):\n",
    "    condition_vals = [  (cross_table['sex_id_x'],cross_table['sex_id_y']),\n",
    "                (cross_table['cesarean_section'],\n",
    "                 pd.Series([x in cesarean_ids for x in cross_table['delivery_route_id']])),\n",
    "                (cross_table['zip_code'],cross_table['mothers_residence_zip_code']),\n",
    "                (cross_table['race_id_x'],cross_table['race_id_y']),\n",
    "                (cross_table['ethnicity_id_x'],cross_table['ethnicity_id_y']),\n",
    "                (cross_table['payer_type_of_coverage_id_x'],cross_table['payer_type_of_coverage_id_y']),\n",
    "                ((cross_table['principal_language_spoken_x'].str[:3]).str.lower(),\n",
    "                 (cross_table['principal_language_spoken_y'].str[:3]).str.lower()),\n",
    "                (cross_table['discharged_on_x'],cross_table['discharged_on_y']),\n",
    "                (cross_table['payer_category_id_x'],cross_table['payer_category_id_y']),\n",
    "                (cross_table['plan_code_number_x'],cross_table['plan_code_number_y']),\n",
    "                ((cross_table['plurality_group_id']==1),(cross_table['plurality']==1)),\n",
    "                (cross_table['birth_weight_group_id'],\n",
    "                     l.digitize_series(cross_table['birth_weight'],bw_bins)),\n",
    "                (cross_table['gestational_age_group_id'],\n",
    "                     l.digitize_series(cross_table['gestational_age_ob_estimate']/7,age_bins))  ] \n",
    "    return(condition_vals)\n",
    "\n",
    "def getBools(cross_table):\n",
    "    \n",
    "    def bool_test(condition_val_pair):\n",
    "        # Exact matching of fields\n",
    "        condA,condB = condition_val_pair\n",
    "        #condA,condB = pd.to_numeric(condA),pd.to_numeric(condB)\n",
    "        fields_notnull = np.logical_and(condA.notnull(),condB.notnull())\n",
    "        return(np.vstack([np.array(condA.values==condB.values)&fields_notnull,\n",
    "                          np.array(condA.values!=condB.values)&fields_notnull]))\n",
    "    \n",
    "    def bool_test_complex(condition_val_pair):\n",
    "        # 'Fuzzy' matching of fields\n",
    "        condA,condB = condition_val_pair\n",
    "        fields_notnull = np.logical_and(condA.notnull(),condB.notnull())\n",
    "        condA,condB = pd.to_numeric(condA),pd.to_numeric(condB)\n",
    "        condA,condB = np.nan_to_num(condA),np.nan_to_num(condB)\n",
    "        return(np.vstack([np.squeeze(np.diff(zip(condA,condB))==0)&fields_notnull,\n",
    "                          np.squeeze(np.diff(zip(condA,condB))==1)&fields_notnull,\n",
    "                          np.squeeze(np.diff(zip(condA,condB))>1)&fields_notnull]))\n",
    "\n",
    "    condition_vals = get_condition_vals(cross_table)\n",
    "    simple_bools = [bool_test(x) for x in condition_vals[0:simple_feature_num]] # Simple features\n",
    "    complex_bools = [bool_test_complex(x) for x in condition_vals[simple_feature_num:]] # Complex features\n",
    "\n",
    "    return(np.concatenate(simple_bools+complex_bools).T)\n",
    "\n",
    "#def getMissing(cross_table):\n",
    "#    def none_test(condition_val_pair):\n",
    "#        condA,condB = condition_val_pair\n",
    "#        aNones = [x is None for x in condA]\n",
    "#        bNones = [x is None for x in condB]\n",
    "#        return(np.vstack([np.logical_or(aNones,bNones),np.logical_or(aNones,bNones)]))\n",
    "#   condition_vals = get_condition_vals(cross_table)\n",
    "#    return(np.concatenate([none_test(x) for x in condition_vals]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all possible values for 1st blocking field ('hospital_id')\n",
    "stmt = '''\n",
    "SELECT DISTINCT patient_discharges.hospital_id\n",
    "FROM patient_discharges \n",
    "UNION\n",
    "SELECT DISTINCT births.hospital_id\n",
    "FROM births;'''\n",
    "block_list1 = [x[0] for x in l.exec_sql(stmt).values.tolist()]\n",
    "#block_list1_train = [block_list1[i] for i in [0,2]]\n",
    "#block_list1_valid = [block_list1[i] for i in [1,3]]\n",
    "\n",
    "# Find all possible values for 2nd blocking field ('date_of_delivery')\n",
    "stmt = '''\n",
    "SELECT DISTINCT births.date_of_delivery\n",
    "FROM births;'''\n",
    "block_list2 = [x[0] for x in l.exec_sql(stmt).values.tolist()]\n",
    "#block_list2_train = block_list2[200:275]\n",
    "#block_list2_valid = block_list2[400:475]\n",
    "\n",
    "# List all possible combinations of blocks\n",
    "block_prod = [(str(x),str(y)) for x in block_list1 for y in block_list2]\n",
    "np.random.shuffle(block_prod)\n",
    "block_prod_train = block_prod[:200]\n",
    "block_prod_valid = block_prod[200:225]\n",
    "\n",
    "# Assign strings to select each block\n",
    "blocking_stmt1 = '''\n",
    "        SELECT patient_discharges.id AS pdd_id, newborns.id AS newb_id,%s \n",
    "        FROM %s\n",
    "        WHERE patient_discharges.hospital_id = %r\n",
    "        AND patient_discharges.date_of_birth = %r;\n",
    "        '''\n",
    "blocking_stmt2 = '''\n",
    "        SELECT births.id AS bc_id,%s\n",
    "        FROM %s\n",
    "        WHERE births.hospital_id = %r\n",
    "        AND births.date_of_delivery = %r;\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classifiers\n",
    "- Create [probabilistic] and [perceptron] classifier (each to be trained on subset of features ['simple' vs. 'complex'])\n",
    "[perceptron]: http://glowingpython.blogspot.com/2011/10/perceptron.html\n",
    "[probabilistic]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5005943/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate_pt = 0.001 # small, constant learning rate\n",
    "learning_rate_nn = 0.001\n",
    "learning_rate_km = 0.01\n",
    "\n",
    "# Create instances of classifiers\n",
    "classifiers = [Probabilistic(simple_features),\n",
    "                Probabilistic(feature_vals),\n",
    "                Perceptron(simple_features,learningrate = learning_rate_pt),\n",
    "                Perceptron(feature_vals,learningrate = learning_rate_pt),\n",
    "                NeuralNetwork(feature_vals,20,1,learningrate = learning_rate_nn),\n",
    "                KerasModel(feature_vals,10,1,learningrate = learning_rate_km)]\n",
    "\n",
    "#kmodel = KerasModel(feature_vals,16,1,learningrate = learning_rate_km)\n",
    "\n",
    "classifier_names = ['prob_s','prob_c','pt_s','pt_c','nn_c','k_mod']\n",
    "\n",
    "color_list = ['b','g','r','c','m','y'][slice(len(classifiers))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over each indexing block\n",
    "- Loop over each block and convert to pandas dataframe\n",
    "- Cross join the features-of-interest from both blocks\n",
    "- Apply conditional statements to each column of dataframe\n",
    "- Return match score from each learner\n",
    "- Maximize pairing with Kuhn-Munkres (i.e. Hungarian) Algorithm [more info]\n",
    "- Compare guesses to truth, update weights/probabilities\n",
    "\n",
    "[more info]: https://pypi.python.org/pypi/munkres/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #0 [ blockA: 5 records, blockB: 5 records ]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:\n",
      "/tmp/try_flags_FAnhBO.c:4:19: fatal error: cudnn.h: No such file or directory\n",
      " #include <cudnn.h>\n",
      "                   ^\n",
      "compilation terminated.\n",
      "\n",
      "Mapped name None to device cuda: GeForce GT 610 (0000:07:00.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 [ blockA: 3 records, blockB: 3 records ]     "
     ]
    }
   ],
   "source": [
    "class_prog = [True] * len(classifiers)\n",
    "\n",
    "block_duration = []\n",
    "epoch_duration = []\n",
    "epoch_count = 0\n",
    "verb_str = '\\rEpoch #{} [ blockA: {} records, blockB: {} records ]   ' # verbose output\n",
    "\n",
    "while True:\n",
    "    epoch_start = time.time() # Measure epoch duration\n",
    "\n",
    "    def run_blocks(block_prod_list):\n",
    "        \n",
    "        big_bool = pd.DataFrame(columns=feature_vals)  \n",
    "        \n",
    "        for block1, block2 in block_prod_list:\n",
    "\n",
    "            block_start = time.time() # Measure block duration\n",
    "\n",
    "            # Create blocks\n",
    "            blockA = l.exec_sql(blocking_stmt1 % (\",\".join(tableA_fields),tableA,block1,block2))\n",
    "            blockB = l.exec_sql(blocking_stmt2 % (\",\".join(tableB_fields),tableB,block1,block2))\n",
    "\n",
    "            if verbose:\n",
    "                sys.stdout.write(verb_str.format(epoch_count, len(blockA), len(blockB)))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            # Check that neither block is empty - If empty, skip to next record-pair in loop\n",
    "            if (len(blockA)==0) or (len(blockB)==0):\n",
    "                continue\n",
    "\n",
    "            # Cross-join both blocks\n",
    "            cross_table = l.df_crossjoin(blockA, blockB)\n",
    "\n",
    "            # Count field matches and dump each into new column of dataframe\n",
    "            bool_table = pd.DataFrame.from_items(zip(feature_vals,getBools(cross_table).T))\n",
    "\n",
    "            # Add record-id columns to boolean table\n",
    "            bool_table['newb_id'] = cross_table['newb_id'].values # Actual newborn id\n",
    "            bool_table['bc_id'] = cross_table['bc_id'].values  # Actual bc id\n",
    "            bool_table['prev_newb_id'] = cross_table['newborn_id'].values # Originally matched newborn id \n",
    "\n",
    "            # Compare with previously-linked newborn id\n",
    "            bool_table['real_match'] = (cross_table['newborn_id']==cross_table['newb_id']).values \n",
    "            for x in classifier_names:\n",
    "                bool_table['match_'+x] = False # Create new columns for later\n",
    "            \n",
    "            # Get guesses from classifiers\n",
    "            record_id = bool_table[['newb_id','bc_id']]\n",
    "            for x,y in zip(classifiers,classifier_names):\n",
    "                link_inds,link_score = x.query(bool_table[x.features],record_id) \n",
    "                #bool_table['lscore_'+y] = link_score\n",
    "                bool_table.loc[link_inds,'match_'+y] = True # Label nominees as such  \n",
    "\n",
    "            #link_inds,link_score = kmodel.query(bool_table[kmodel.features],record_id)\n",
    "            #bool_table.loc[link_inds,'match_kmodel'] = True # Label nominees as such\n",
    "                                   \n",
    "            # Aggregate field-match tables (Booleans) within loop\n",
    "            big_bool = pd.concat([big_bool,bool_table])\n",
    "\n",
    "            # Time duration of each block\n",
    "            block_duration.append(time.time()-block_start)\n",
    "        \n",
    "        return(big_bool)\n",
    "    \n",
    "    ## Check progress of each classifier \n",
    "    big_bool_tr = run_blocks(block_prod_train)\n",
    "    big_bool_val = run_blocks(block_prod_valid)\n",
    "    \n",
    "    # Train classifiers (if still progressing)\n",
    "    train_classifier = lambda x,y: \\\n",
    "        x.train(big_bool_tr[x.features],big_bool_tr['real_match'],big_bool_tr['match_'+y])\n",
    "    map(train_classifier,classifiers,classifier_names)\n",
    "        \n",
    "    ## Measure accuracy of each classifier\n",
    "    #score_list = [((big_bool['match_'+x]==big_bool['real_match'])*1).tolist() for x in classifier_names]\n",
    "    #cur_scores = [sum(x)*100.0/len(x) for x in score_list]\n",
    "    \n",
    "    # Update precision & recall of classifiers\n",
    "    for x,y in zip(classifiers,classifier_names):\n",
    "        x.test_classifier(big_bool_tr['match_'+y],big_bool_tr['real_match'])\n",
    "\n",
    "    # Validate classifiers  \n",
    "    for x,y in zip(classifiers,classifier_names):\n",
    "        x.val_classifier(big_bool_val['match_'+y],big_bool_val['real_match'])\n",
    "\n",
    "    # Compare current iteration performance with previous\n",
    "    cur_iter_qual = [x.train_accuracy_list[-1] for x in classifiers]\n",
    "    if epoch_count>0:\n",
    "        prev_iter_qual = [x.train_accuracy_list[-2] for x in classifiers]\n",
    "        class_prog = np.subtract(cur_iter_qual,prev_iter_qual)>.01\n",
    "    \n",
    "    # If not improving, break from outer loop\n",
    "    if not any(class_prog):\n",
    "        print str.format('\\n'+'-'*80+\"\\nQuality threshold achieved! @ {}\",[ float('%.2f' % x) for x in cur_iter_qual ])        \n",
    "        break\n",
    "\n",
    "    # Time duration of each iteration\n",
    "    epoch_duration.append(time.time()-epoch_start)\n",
    "    \n",
    "    epoch_count += 1 # Increment epoch counter\n",
    "    \n",
    "    if verbose:\n",
    "        print str.format('\\nAverage block duration: {0:.2f} seconds', np.mean(block_duration))\n",
    "        print str.format(\"Accuracy: {}\", [ float('%.2f' % x) for x in cur_iter_qual ])\n",
    "        print str.format('Average epoch duration: {0:.3f} minutes', np.mean(epoch_duration)/60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracy for each classifier over all epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.style.use('seaborn')\n",
    "\n",
    "def plot_classifiers(ax,train_list,val_list,title,xlabel):\n",
    "\n",
    "    M_tr = np.array(train_list).T\n",
    "    M_val = np.array(val_list).T\n",
    "    for i in range(M_tr.shape[1]):\n",
    "        ax.plot(range(M_tr.shape[0]), M_tr[:,i],'-',color=color_list[i],\n",
    "                 label=classifier_names[i] + ' max [train:' + str('%.2f' % np.max(M_tr[:,i])) + \n",
    "                 ' valid:' + str('%.2f' % np.max(M_val[:,i])) + ']')\n",
    "    \n",
    "    for i in range(M_val.shape[1]):\n",
    "        ax.plot(range(M_val.shape[0]), M_val[:,i],'--',color=color_list[i])\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_title(title)\n",
    "\n",
    "nrow = 3; ncol = 2\n",
    "fig = plt.figure(figsize=(nrow,ncol))\n",
    "\n",
    "ax1 = fig.add_subplot(nrow,ncol,1)\n",
    "plt.pie([len(big_bool_tr),len(big_bool_val)],\n",
    "        labels=['training set('+str(len(big_bool_tr))+' pairs)',\n",
    "                'validation set('+str(len(big_bool_val))+' pairs)'],autopct='%1.1f%%')\n",
    "ax1.axis('equal')\n",
    "\n",
    "len_tested = len(block_prod_train)+len(block_prod_valid)\n",
    "ax2 = fig.add_subplot(nrow,ncol,2)\n",
    "plt.pie([len_tested,len(block_prod)-len_tested],\n",
    "        labels=['tested data('+str(len_tested)+' blocks)',\n",
    "                'untested data('+str(len(block_prod))+' blocks)'],autopct='%1.1f%%')\n",
    "ax2.axis('equal')\n",
    "\n",
    "ax3 = fig.add_subplot(nrow,ncol,3)\n",
    "plot_train_list = [o.train_accuracy_list for o in classifiers]\n",
    "plot_val_list = [o.val_accuracy_list for o in classifiers]\n",
    "plot_classifiers(ax3,plot_train_list,plot_val_list,'accuracy(%)','')\n",
    "\n",
    "ax4 = fig.add_subplot(nrow,ncol,4)\n",
    "plot_train_list = [o.train_fscore_list for o in classifiers]\n",
    "plot_val_list = [o.val_fscore_list for o in classifiers]\n",
    "plot_classifiers(ax4,plot_train_list,plot_val_list,'f-measure(%)','')\n",
    "\n",
    "ax5 = fig.add_subplot(nrow,ncol,5)\n",
    "plot_train_list = [o.train_precision_list for o in classifiers]\n",
    "plot_val_list = [o.val_precision_list for o in classifiers]\n",
    "plot_classifiers(ax5,plot_train_list,plot_val_list,'precision(%)','')\n",
    "\n",
    "ax6 = fig.add_subplot(nrow,ncol,6)\n",
    "plot_train_list = [o.train_recall_list for o in classifiers]\n",
    "plot_val_list = [o.val_recall_list for o in classifiers]\n",
    "plot_classifiers(ax6,plot_train_list,plot_val_list,'recall(%)','epoch')\n",
    "\n",
    "fig.subplots_adjust(hspace=.2)\n",
    "fig.set_size_inches(7*ncol,4*nrow)\n",
    "plt.show()\n",
    "fig.savefig('classifier_val_scores.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot summary of record data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2; ncol = 2\n",
    "fig = plt.figure(figsize=(nrow,ncol))\n",
    "\n",
    "ax1 = fig.add_subplot(nrow,ncol,1)\n",
    "bc_hosp_str = \"SELECT births.hospital_id,COUNT(*) as count FROM births GROUP BY births.hospital_id;\"\n",
    "bc_hosp_vals = l.exec_sql(bc_hosp_str)\n",
    "bc_tot = l.exec_sql(\"SELECT COUNT(*) FROM births\")\n",
    "bc_hosp_vals.plot.bar(x='hospital_id',ax=ax1,title='births.hospital_id [sum:' + str(bc_tot.values[0][0]) + ']')\n",
    "\n",
    "ax2 = fig.add_subplot(nrow,ncol,2)\n",
    "pdd_hosp_str = \"SELECT patient_discharges.hospital_id,COUNT(*) as count FROM patient_discharges GROUP BY patient_discharges.hospital_id;\"\n",
    "pdd_hosp_vals = l.exec_sql(pdd_hosp_str)\n",
    "pdd_tot = l.exec_sql(\"SELECT COUNT(*) FROM patient_discharges\")\n",
    "pdd_hosp_vals.plot.bar(x='hospital_id',ax=ax2,title='patient_discharges.hospital_id [sum:' + str(pdd_tot.values[0][0]) + ']')\n",
    "\n",
    "ax3 = fig.add_subplot(nrow,ncol,3)\n",
    "bc_bday_str = \"SELECT births.date_of_delivery,COUNT(*) as count FROM births GROUP BY births.date_of_delivery;\"\n",
    "bc_bday_vals = l.exec_sql(bc_bday_str)\n",
    "bc_bday_vals.plot(ax=ax3,x = 'date_of_delivery',title = 'births.date_of_delivery')\n",
    "\n",
    "ax4 = fig.add_subplot(nrow,ncol,4)\n",
    "pdd_bday_str = \"SELECT patient_discharges.date_of_birth,COUNT(*) as count FROM patient_discharges GROUP BY patient_discharges.date_of_birth;\"\n",
    "pdd_bday_vals = l.exec_sql(pdd_bday_str)\n",
    "pdd_bday_vals.plot(ax=ax4,x = 'date_of_birth', title = 'patient_discharges.date_of_birth')\n",
    "\n",
    "fig.subplots_adjust(hspace=.4)\n",
    "fig.set_size_inches(4.875*ncol,4*nrow)\n",
    "fig.savefig('block_sizes.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show table of weights/probabilities for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"\"><tr style=\"\"><td style=\"\">classifier</td><td style=\"\">sex_id_match</td><td style=\"\">sex_id_nomatch</td><td style=\"\">c_section_match</td><td style=\"\">c_section_nomatch</td><td style=\"\">zip_code_match</td><td style=\"\">zip_code_nomatch</td><td style=\"\">race_match</td><td style=\"\">race_nomatch</td><td style=\"\">ethnicity_match</td><td style=\"\">ethnicity_nomatch</td><td style=\"\">payer_type_of_coverage_id_match</td><td style=\"\">payer_type_of_coverage_id_nomatch</td><td style=\"\">language_spoken_match</td><td style=\"\">language_spoken_nomatch</td><td style=\"\">discharge_match</td><td style=\"\">discharge_nomatch</td><td style=\"\">payer_category_id_match</td><td style=\"\">payer_category_id_nomatch</td><td style=\"\">plan_code_number_match</td><td style=\"\">plan_code_number_nomatch</td><td style=\"\">plurality_match</td><td style=\"\">plurality_nomatch</td><td style=\"\">weight_group_id_match</td><td style=\"\">weight_group_id_fuzzymatch</td><td style=\"\">weight_group_id_nomatch</td><td style=\"\">gest_age_group_id_match</td><td style=\"\">gest_age_group_id_fuzzymatch</td><td style=\"\">gest_age_group_id_nomatch</td><td style=\"\">bias</td></tr><tr style=\"\"><td style=\"\">prob_simple</td><td style=\"\">0.981024667932</td><td style=\"\">0.0185009487666</td><td style=\"\">0.992409867173</td><td style=\"\">0.00759013282732</td><td style=\"\">0.895161290323</td><td style=\"\">0.103889943074</td><td style=\"\">0.890891840607</td><td style=\"\">0.102466793169</td><td style=\"\">0.933586337761</td><td style=\"\">0.0645161290323</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.916034155598</td><td style=\"\">0.0787476280835</td><td style=\"\">0.890417457306</td><td style=\"\">0.109582542694</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.996204933586</td><td style=\"\">0.00379506641366</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td></tr><tr style=\"\"><td style=\"\">prob_complex</td><td style=\"\">0.981024667932</td><td style=\"\">0.0185009487666</td><td style=\"\">0.992409867173</td><td style=\"\">0.00759013282732</td><td style=\"\">0.895161290323</td><td style=\"\">0.103889943074</td><td style=\"\">0.890891840607</td><td style=\"\">0.102466793169</td><td style=\"\">0.933586337761</td><td style=\"\">0.0645161290323</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.916034155598</td><td style=\"\">0.0787476280835</td><td style=\"\">0.890417457306</td><td style=\"\">0.109582542694</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.0</td><td style=\"\">0.996204933586</td><td style=\"\">0.00379506641366</td><td style=\"\">0.076375711575</td><td style=\"\">0.00569259962049</td><td style=\"\">0.000474383301708</td><td style=\"\">0.0445920303605</td><td style=\"\">0.0716318785579</td><td style=\"\">0.00189753320683</td><td style=\"\">nan</td></tr><tr style=\"\"><td style=\"\">perc_simple</td><td style=\"\">14.9756052578</td><td style=\"\">-14.9821836876</td><td style=\"\">0.165228567641</td><td style=\"\">-0.165705402598</td><td style=\"\">16.9466069364</td><td style=\"\">-16.9343576373</td><td style=\"\">15.8023694142</td><td style=\"\">-15.8127165231</td><td style=\"\">12.6697030038</td><td style=\"\">-12.6692080655</td><td style=\"\">0.00902179801272</td><td style=\"\">0.00555401178594</td><td style=\"\">3.33025667212</td><td style=\"\">-3.33002813906</td><td style=\"\">2.00377015014</td><td style=\"\">-2.01972945706</td><td style=\"\">0.00178702274153</td><td style=\"\">-0.00532458834501</td><td style=\"\">0.000680941094566</td><td style=\"\">0.00224023011689</td><td style=\"\">1.95375899456</td><td style=\"\">-1.95284294058</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">nan</td><td style=\"\">0.00894549382414</td></tr><tr style=\"\"><td style=\"\">perc_complex</td><td style=\"\">0.625412755749</td><td style=\"\">-0.617133943728</td><td style=\"\">1.26053665737</td><td style=\"\">-1.25903667607</td><td style=\"\">1.69771383109</td><td style=\"\">-1.68794997676</td><td style=\"\">0.238962895236</td><td style=\"\">-0.247801759969</td><td style=\"\">0.114620767972</td><td style=\"\">-0.112326890011</td><td style=\"\">-0.00770795103945</td><td style=\"\">0.00970571567555</td><td style=\"\">0.231849030812</td><td style=\"\">-0.230658364141</td><td style=\"\">0.807780056103</td><td style=\"\">-0.796405555595</td><td style=\"\">-0.00487802246161</td><td style=\"\">-0.0040530087758</td><td style=\"\">-0.000670760572659</td><td style=\"\">-0.00100497836549</td><td style=\"\">1.91322063187</td><td style=\"\">-1.91371700726</td><td style=\"\">0.563531152275</td><td style=\"\">-0.189731123446</td><td style=\"\">-0.29415407207</td><td style=\"\">-0.00994070815628</td><td style=\"\">0.420105650789</td><td style=\"\">-0.357070636284</td><td style=\"\">0.00102084488835</td></tr></table>"
      ],
      "text/plain": [
       "<itable.itable.PrettyTable at 0x7ff1362cccd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itable\n",
    "\n",
    "# Assemble table elements into dataframe\n",
    "pt_simple_weights = classifiers[2].weights.tolist()[:-1] + \\\n",
    "    [None]*len(complex_features) + [classifiers[2].weights.tolist()[-1]]\n",
    "\n",
    "weight_list = [['prob_simple'] + classifiers[0].m_probs.tolist() + [None],\n",
    "               ['prob_complex'] + classifiers[1].m_probs.tolist() + [None],\n",
    "               ['perc_simple'] + pt_simple_weights,\n",
    "               ['perc_complex'] + classifiers[3].weights.tolist()]\n",
    "df = pd.DataFrame(weight_list, columns=['classifier']+feature_vals+['bias'])\n",
    "\n",
    "# Save table as html file\n",
    "my_file = open('weights.html', 'w')\n",
    "my_file.write(df.to_html())\n",
    "#pt_simple_weights = classifiers[2].weights.tolist()\n",
    "my_file.close()\n",
    "\n",
    "# Show table as ipython figure\n",
    "itable.PrettyTable(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize and export 'wrong answers' to spreadsheet (.csv) files [1 spreadsheet/classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate 'str' and 'instance' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-65972798a369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Gather incorrect matches for each classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscore_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_bool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'match_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbig_bool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'real_match'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate 'str' and 'instance' objects"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Select features to export\n",
    "feature_list = ['bc_id','real_match','newb_id']+feature_vals\n",
    "\n",
    "# Gather incorrect matches for each classifier\n",
    "score_list = [((big_bool['match_'+x]==big_bool['real_match'])*1).tolist() for x in classifiers]\n",
    "\n",
    "for sc,cl in zip(score_list,classifiers):\n",
    "    errors = big_bool[feature_list].iloc[[x==0 for x in sc],:].sort(['bc_id','real_match'], ascending=[1,0])\n",
    "    errors.to_csv('linkage_error_'+cl+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
